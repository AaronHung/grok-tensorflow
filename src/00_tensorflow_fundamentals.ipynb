{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we'are going to cover some of the most fundamental concepts of tensors using TensorFlow\n",
    "\n",
    "#### More specifically, we're going to cover:\n",
    "* Introduction to tensors\n",
    "* Getting information from tensors\n",
    "* Manipulating tensors\n",
    "* Tensors & NumPy\n",
    "* Using @tf.function (a way to speed up your regular Python functions)\n",
    "* Using GPUs with TensorFlow (or TPUs)\n",
    "* Exercise to try for yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 12:21:16.743596: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-03-24 12:21:16.743770: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-03-24 12:21:16.743780: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-03-24 12:21:16.743995: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-24 12:21:16.744011: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensors with tf.constant()\n",
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of a tensor (`ndim` stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector\n",
    "vector = tf.constant([10, 10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10 10], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the dimension of our vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a matrix (has more than 1 dimension)\n",
    "matrix = tf.constant([[10, 7], [7, 10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float16, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float16)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another matrix\n",
    "another_matrix = tf.constant([[1., 2., 3.],\n",
    "    [4., 5., 6.],\n",
    "    [7., 8., 9.]], dtype=tf.float16)\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the ndim of the another_matrix\n",
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "    [4, 5, 6]],\n",
    "    [[7, 8, 9],\n",
    "    [10, 11, 12]],\n",
    "    [[13, 14, 15],\n",
    "    [16, 17, 18]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we've created so far:\n",
    "\n",
    "* Scalar: a single number\n",
    "* Vector: a number with direction (e.g. wind speed and direction)\n",
    "* Matrix: a 2-dimensional array of numbers\n",
    "* Tensor: an n-dimensional array of numbers (when n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating tensors with `tf.Variable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.variables.Variable"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the same tensor with tf.Variable() as above\n",
    "\n",
    "changeable_tensor = tf.Variable([10, 7])\n",
    "unchangeable_tensor = tf.constant([10, 7])\n",
    "changeable_tensor, unchangeable_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Let's try change one of the elements in our changeable tensor \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mchangeable_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m = \u001b[32m7\u001b[39m\n\u001b[32m      4\u001b[39m changeable_tensor\n",
      "\u001b[31mTypeError\u001b[39m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Let's try change one of the elements in our changeable tensor \n",
    "\n",
    "changeable_tensor[0] = 7\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error happens because changeable_tensor is likely a TensorFlow tf.Variable, which does not support item assignment using standard Python syntax like changeable_tensor[0] = 7.\n",
    "\n",
    "✅ Aaron's Notes - Why it happens:\n",
    "tf.Variable is a mutable container for TensorFlow tensors, but you can't modify it in-place with normal indexing. Instead, TensorFlow provides specific methods to change its contents, such as `assign`, `assign_sub`, `assign_add`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([99,  7], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about we try .assign()\n",
    "\n",
    "changeable_tensor[0].assign(99)\n",
    "changeable_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Let's try change our unchangeable tensor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43munchangeable_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m = \u001b[32m7\u001b[39m\n\u001b[32m      4\u001b[39m unchangeable_tensor\n",
      "\u001b[31mTypeError\u001b[39m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Let's try change our unchangeable tensor\n",
    "\n",
    "unchangeable_tensor[0] = 7\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Let's try `assign` to unchangeable constant\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43munchangeable_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43massign\u001b[49m(\u001b[32m99\u001b[39m)\n\u001b[32m      4\u001b[39m unchangeable_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:260\u001b[39m, in \u001b[36mTensor.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mravel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtranspose\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreshape\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclip\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    253\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtolist\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m    254\u001b[39m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[32m    255\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    256\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[33m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[33m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[33m  \u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "# Let's try `assign` to unchangeable constant\n",
    "\n",
    "unchangeable_tensor[0].assign(99)\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🔑 Rarely in practice will you need to decide whether to use `tf.constant` or `tf.Variable` to create tensors, as TensorFlow does this for you. However, if in doubt, use `tf.constant` and change it later if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating random tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random tensors are tensors of some abitrary size which contain random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.75658023, -0.06854693],\n",
       "        [ 0.07595028, -1.2573844 ],\n",
       "        [-0.23193759, -1.8107857 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[-0.75658023, -0.06854693],\n",
       "        [ 0.07595028, -1.2573844 ],\n",
       "        [-0.23193759, -1.8107857 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       " array([[ True,  True],\n",
       "        [ True,  True],\n",
       "        [ True,  True]])>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two random (but the same) tensors\n",
    "\n",
    "random_1 = tf.random.Generator.from_seed(42) # set seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3, 2))\n",
    "random_2 = tf.random.Generator.from_seed(42)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "\n",
    "# Are they equal?\n",
    "random_1, random_2, random_1 == random_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_1 == random_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the order of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [10,  7],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle a tensor (valueable for when you want to shuffle your data so the inherent order doesn't effect learning)\n",
    "\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                           [3, 4],\n",
    "                           [2, 5]])\n",
    "                        \n",
    "tf.random.shuffle(not_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 3,  4],\n",
       "       [10,  7],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle our non-shuffled tensor\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle our non-shuffled tensor\n",
    "tf.random.set_seed(42)\n",
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🛠️ **Exercise:** \n",
    "1. Read through TensorFlow documentation on [random seed generation](https://www.tensorflow.org/api_docs/python/tf/random/set_seed)\n",
    "2. And, practice writing 5 random tensors and shufffle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before shuffling: ------------------------------\n",
      "tf.Tensor(\n",
      "[[0.6645621  0.44100678]\n",
      " [0.3528825  0.46448255]\n",
      " [0.03366041 0.68467236]], shape=(3, 2), dtype=float32) tf.Tensor(\n",
      "[[0.68789124 0.48447883]\n",
      " [0.9309944  0.252187  ]\n",
      " [0.73115396 0.89256823]], shape=(3, 2), dtype=float32)\n",
      "\n",
      "after shuffling: ------------------------------\n",
      "tf.Tensor(\n",
      "[[0.03366041 0.68467236]\n",
      " [0.3528825  0.46448255]\n",
      " [0.6645621  0.44100678]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.73115396 0.89256823]\n",
      " [0.9309944  0.252187  ]\n",
      " [0.68789124 0.48447883]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Ex1: random tensors and shuffled (this is eager mode)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"before shuffling:\", 30*\"-\")\n",
    "r1 = tf.random.uniform([3, 2])\n",
    "r2 = tf.random.uniform([3, 2])\n",
    "print(r1, r2)\n",
    "\n",
    "print(\"\\nafter shuffling:\", 30*\"-\")\n",
    "print(tf.random.shuffle(r1))\n",
    "print(tf.random.shuffle(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before shuffling: ------------------------------\n",
      "Tensor(\"random_uniform/RandomUniform:0\", shape=(3, 2), dtype=float32) Tensor(\"random_uniform_1/RandomUniform:0\", shape=(3, 2), dtype=float32)\n",
      "\n",
      "after shuffling: ------------------------------\n",
      "Tensor(\"RandomShuffle:0\", shape=(3, 2), dtype=float32)\n",
      "Tensor(\"RandomShuffle_1:0\", shape=(3, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:12:14.985377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Ex2 - shuffle with decorators! (This is graph mode)\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "@tf.function\n",
    "def shuffle_test():\n",
    "    print(\"before shuffling:\", 30*\"-\")\n",
    "    r1 = tf.random.uniform([3, 2])\n",
    "    r2 = tf.random.uniform([3, 2])\n",
    "    print(r1, r2)\n",
    "    print(\"\\nafter shuffling:\", 30*\"-\")\n",
    "    print(tf.random.shuffle(r1))\n",
    "    print(tf.random.shuffle(r2))\n",
    "\n",
    "shuffle_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before shuffling: ====================\n",
      "Tensor 0: \n",
      "[[0.6645621  0.44100678]\n",
      " [0.3528825  0.46448255]] \n",
      "\n",
      "Tensor 1: \n",
      "[[0.68789124 0.48447883]\n",
      " [0.9309944  0.252187  ]] \n",
      "\n",
      "Tensor 2: \n",
      "[[0.7413678  0.62854624]\n",
      " [0.01738465 0.3431449 ]] \n",
      "\n",
      "After shuffling: ====================\n",
      "Tensor 0: \n",
      "[[0.7413678  0.62854624]\n",
      " [0.01738465 0.3431449 ]] \n",
      "\n",
      "Tensor 1: \n",
      "[[0.68789124 0.48447883]\n",
      " [0.9309944  0.252187  ]] \n",
      "\n",
      "Tensor 2: \n",
      "[[0.6645621  0.44100678]\n",
      " [0.3528825  0.46448255]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ex3 - Eager Mode Example:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create 5 random tensors and put them into a list\n",
    "tensors = [tf.random.uniform([2, 2]) for _ in range(3)]\n",
    "\n",
    "print(\"Before shuffling:\", 20*\"=\")\n",
    "for i, t in enumerate(tensors):\n",
    "    print(f\"Tensor {i}: \\n{t} \\n\")\n",
    "    \n",
    "# Stack them into a single tensor so we can shuffle them\n",
    "stacked = tf.stack(tensors)  # shape = (5, 2, 2)\n",
    "shuffled = tf.random.shuffle(stacked)\n",
    "\n",
    "print(\"After shuffling:\", 20*\"=\")\n",
    "for i, t in enumerate(shuffled):\n",
    "    print(f\"Tensor {i}: \\n{t} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above exercise, the **shuffle only happens across the first dimension,**, i.e., **between Tensor 0, 1, and 2**  -- not insdie each individual 2x2 tensor.\n",
    "\n",
    "Let's say we have:\n",
    "```python\n",
    "tensors = [A, B, C]  # where each is a 2×2 tensor\n",
    "stacked = tf.stack(tensors)  # shape = [3, 2, 2]\n",
    "```\n",
    "\n",
    "This give us a 3D tensor like:\n",
    "```lua\n",
    "[\n",
    "  [[a1, a2],\n",
    "   [a3, a4]],   # Tensor 0\n",
    "\n",
    "  [[b1, b2],\n",
    "   [b3, b4]],   # Tensor 1\n",
    "\n",
    "  [[c1, c2],\n",
    "   [c3, c4]]    # Tensor 2\n",
    "]\n",
    "```\n",
    "When we call:\n",
    "`tf.random.shuffle(stacked)`\n",
    "\n",
    "We only are shuffling **the outer dimension** (axis 0), i.e., we're just changing the order of Tensor 0, Tensor 1, Tensor 2. as below:\n",
    "\n",
    "```lua\n",
    "→\n",
    "[\n",
    "  [[c1, c2],\n",
    "   [c3, c4]],   # Was Tensor 2\n",
    "\n",
    "  [[a1, a2],\n",
    "   [a3, a4]],   # Was Tensor 0\n",
    "\n",
    "  [[b1, b2],\n",
    "   [b3, b4]]    # Was Tensor 1\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ **What if we want to shuffle inside** each tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before shuffling INSIDE TENSOR: ====================\n",
      "Tensor 0: \n",
      "[[0.6645621  0.44100678]\n",
      " [0.3528825  0.46448255]] \n",
      "\n",
      "Tensor 1: \n",
      "[[0.68789124 0.48447883]\n",
      " [0.9309944  0.252187  ]] \n",
      "\n",
      "Tensor 2: \n",
      "[[0.7413678  0.62854624]\n",
      " [0.01738465 0.3431449 ]] \n",
      "\n",
      "After shuffling INSDIE TENSOR: ====================\n",
      "Tensor 0: \n",
      "[[0.3528825  0.46448255]\n",
      " [0.6645621  0.44100678]] \n",
      "\n",
      "Tensor 1: \n",
      "[[0.68789124 0.48447883]\n",
      " [0.9309944  0.252187  ]] \n",
      "\n",
      "Tensor 2: \n",
      "[[0.01738465 0.3431449 ]\n",
      " [0.7413678  0.62854624]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# shuffle inside\n",
    "\n",
    "print(\"Before shuffling INSIDE TENSOR:\", 20*\"=\")\n",
    "for i, t in enumerate(tensors):\n",
    "    print(f\"Tensor {i}: \\n{t} \\n\")\n",
    "\n",
    "shuffled_inside = [tf.random.shuffle(t) for t in tensors]\n",
    "\n",
    "print(\"After shuffling INSDIE TENSOR:\", 20*\"=\")\n",
    "for i, t in enumerate(shuffled_inside):\n",
    "    print(f\"Tensor {i}: \\n{t} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if set global seed\n",
    "#### If both the global and the operation seed are set: \n",
    "> - Both seeds are used in conjunction to determine the random sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above setting - **Both global and op-level seed are set** has the following behavior:\n",
    "\n",
    "> #### - this is the `most stable` and `deterministi` setup\n",
    "> #### - Combines both seeds deterministic to generate the result\n",
    "> #### - We'll get `the same output` every time, even accross many random ops, and more robust to TensorFlow version changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # global level random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)  # operation level random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # global level random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)  # operation level random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]], dtype=int32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # global level random seed\n",
    "tf.random.shuffle(not_shuffled, seed=42)  # operation level random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⬆️ same result each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like if we want our shuffled tensors to be in the same order, we've got6 to use the global level random seed as the operation level random seed:\n",
    "\n",
    "> **Rule 4**: if both the global and the op-seed are set: Both seeds are used in conjunmtion to determine the random sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ways to make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "tf.ones([10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "tf.zeros(shape=(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn Numpy arrays into tensors\n",
    "\n",
    "#### The mian difference between Numpy arrays and TensorFlow tensors is that tensors can be run on a GPU (much faster for numerical computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also turn NumPy arrays into tensors\n",
    "\n",
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype=np.int32)  # create a NumPy array between 1 and 25\n",
    "numpy_A\n",
    "\n",
    "# X = tf.constant(some_matrix) # cpaital for matrix or tensor\n",
    "# y = tf.constant(vector)  # non-cap0ital for vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant(numpy_A)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 So What's the Difference?\n",
    "\n",
    "| Feature                     | `tf.constant()`                 | `tf.convert_to_tensor()`        |\n",
    "|----------------------------|----------------------------------|----------------------------------|\n",
    "| Creates a constant tensor  | ✅ Yes                           | ✅ Yes                            |\n",
    "| Accepts NumPy, list, etc.  | ✅ Yes                           | ✅ Yes                            |\n",
    "| Optimized for constants    | ✅                                | ❌ (more general)                |\n",
    "| Used internally in APIs    | ❌                                | ✅                                |\n",
    "| Can handle already-tensors | ❌ Will re-wrap it               | ✅ Returns as-is if already tensor |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ TL;DR – When to use which?\n",
    "\n",
    "| Use Case                              | Recommended |\n",
    "|---------------------------------------|-------------|\n",
    "| You want a fixed tensor (won’t change) | `tf.constant()` |\n",
    "| Writing flexible, general code         | `tf.convert_to_tensor()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
       " array([[[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12]],\n",
       " \n",
       "        [[13, 14, 15, 16],\n",
       "         [17, 18, 19, 20],\n",
       "         [21, 22, 23, 24]]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       " array([[ 1,  2,  3,  4,  5,  6],\n",
       "        [ 7,  8,  9, 10, 11, 12],\n",
       "        [13, 14, 15, 16, 17, 18],\n",
       "        [19, 20, 21, 22, 23, 24]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24], dtype=int32)>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant(numpy_A, shape=(2, 3, 4))\n",
    "B = tf.constant(numpy_A, shape=(4, 6))\n",
    "C = tf.constant(numpy_A)\n",
    "A, B, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### **Getting information from tensors**\n",
    "\n",
    "#### When dealing with tensors we probably want to be aware of the following attributes:\n",
    "\n",
    "| **Attribute** | **Meaning** | **Code** |\n",
    "|---|---|---|\n",
    "| **Shape** |  The length (number of elements) of each of the dimensions of a tensor. | `tensor.shape` |\n",
    "| **Rank** | The number of tensor dimensions. A scalar has rank 0, a vector has rank 1, a matrix is rank 2, a tensor has rank n. | `tensor.ndim` |\n",
    "| **Axis or dimension** | A particular dimension of a tensor. | `tensor[0], tensor[:, 1]...` |\n",
    "| **Size** | The total number of items in the tensor. | `tf.size(tensor)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 tensor (4 dimensions)\\\n",
    "rank_4_tensor = tf.zeros(shape=[2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 5), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4, 5) \n",
      " 4 \n",
      " tf.Tensor(120, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rank_4_tensor.shape, '\\n',\n",
    "    rank_4_tensor.ndim, '\\n',\n",
    "    tf.size(rank_4_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank):  4\n",
      "Shape of a tensor:  (2, 3, 4, 5)\n",
      "Elements along the 0 axis:  (3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of our tensor\n",
    "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank): \", rank_4_tensor.ndim)\n",
    "print(\"Shape of a tensor: \", rank_4_tensor.shape)\n",
    "# print(\"Elements along the 0 axis: \", rank_4_tensor[0].shape)  # wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank):  4\n",
      "Shape of a tensor:  (2, 3, 4, 5)\n",
      "Elements along the 0 axis: 2\n",
      "Elements along the last axis:  5\n",
      "Total number of elements in our tensor:  tf.Tensor(120, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of our tensor\n",
    "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank): \", rank_4_tensor.ndim)\n",
    "print(\"Shape of a tensor: \", rank_4_tensor.shape)\n",
    "# print(\"Elements along the 0 axis: \", rank_4_tensor[0].shape)  # wrong\n",
    "print(\"Elements along the 0 axis:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis: \", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements in our tensor: \", tf.size(rank_4_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank):  4\n",
      "Shape of a tensor:  (2, 3, 4, 5)\n",
      "Elements along the 0 axis: 2\n",
      "Elements along the last axis:  5\n",
      "Total number of elements in our tensor:  tf.Tensor(120, shape=(), dtype=int32)\n",
      "Total number of elements in our tensor:  120\n"
     ]
    }
   ],
   "source": [
    "# Get various attributes of our tensor\n",
    "# Notice the final statement converted to NumPy\n",
    "\n",
    "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank): \", rank_4_tensor.ndim)\n",
    "print(\"Shape of a tensor: \", rank_4_tensor.shape)\n",
    "# print(\"Elements along the 0 axis: \", rank_4_tensor[0].shape)  # wrong\n",
    "print(\"Elements along the 0 axis:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis: \", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements in our tensor: \", tf.size(rank_4_tensor))\n",
    "print(\"Total number of elements in our tensor: \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Indexing tensors\n",
    "\n",
    "#### Tensors can be indexed just like Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=int32, numpy=\n",
       "array([[[[  0,   1,   2,   3,   4],\n",
       "         [  5,   6,   7,   8,   9],\n",
       "         [ 10,  11,  12,  13,  14],\n",
       "         [ 15,  16,  17,  18,  19]],\n",
       "\n",
       "        [[ 20,  21,  22,  23,  24],\n",
       "         [ 25,  26,  27,  28,  29],\n",
       "         [ 30,  31,  32,  33,  34],\n",
       "         [ 35,  36,  37,  38,  39]],\n",
       "\n",
       "        [[ 40,  41,  42,  43,  44],\n",
       "         [ 45,  46,  47,  48,  49],\n",
       "         [ 50,  51,  52,  53,  54],\n",
       "         [ 55,  56,  57,  58,  59]]],\n",
       "\n",
       "\n",
       "       [[[ 60,  61,  62,  63,  64],\n",
       "         [ 65,  66,  67,  68,  69],\n",
       "         [ 70,  71,  72,  73,  74],\n",
       "         [ 75,  76,  77,  78,  79]],\n",
       "\n",
       "        [[ 80,  81,  82,  83,  84],\n",
       "         [ 85,  86,  87,  88,  89],\n",
       "         [ 90,  91,  92,  93,  94],\n",
       "         [ 95,  96,  97,  98,  99]],\n",
       "\n",
       "        [[100, 101, 102, 103, 104],\n",
       "         [105, 106, 107, 108, 109],\n",
       "         [110, 111, 112, 113, 114],\n",
       "         [115, 116, 117, 118, 119]]]], dtype=int32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aaron's reshaping the original matrix\n",
    "\n",
    "rank_4_tensor = tf.reshape(tf.range(120), shape=(2, 3, 4, 5))\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=int32, numpy=\n",
       "array([[[[ 0,  1],\n",
       "         [ 5,  6]],\n",
       "\n",
       "        [[20, 21],\n",
       "         [25, 26]]],\n",
       "\n",
       "\n",
       "       [[[60, 61],\n",
       "         [65, 66]],\n",
       "\n",
       "        [[80, 81],\n",
       "         [85, 86]]]], dtype=int32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 2 elements of each dimensions\n",
    "rank_4_tensor[:2, :2, :2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0 1 2 3 4]]]], shape=(1, 1, 1, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Get the first element from each dimension from each index\n",
    "#   excpet for the final one\n",
    "\n",
    "print(rank_4_tensor[:1, :1, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 4, 5])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 4, 1), dtype=int32, numpy=\n",
       "array([[[[ 0],\n",
       "         [ 5],\n",
       "         [10],\n",
       "         [15]]]], dtype=int32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:1, :1, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 1, 1), dtype=int32, numpy=\n",
       "array([[[[ 0]],\n",
       "\n",
       "        [[20]],\n",
       "\n",
       "        [[40]]]], dtype=int32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:1, :, :1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 1), dtype=int32, numpy=\n",
       "array([[[[ 0]]],\n",
       "\n",
       "\n",
       "       [[[60]]]], dtype=int32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:, :1, :1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23]], dtype=int32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 2 tensor (2 dimensions)\n",
    "\n",
    "rank_2_tensor = tf.reshape(tf.range(24), shape=(4, 6))\n",
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 6]), 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.shape, rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=23>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last item of each row of our rank 2 tensor\n",
    "\n",
    "rank_2_tensor[-1, -1]  # wrong answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[23]], dtype=int32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last item of each row of our rank 2 tensor\n",
    "\n",
    "rank_2_tensor[-1:, -1:]  # wrong answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 5, 11, 17, 23], dtype=int32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last item of each row of our rank 2 tensor\n",
    " \n",
    "rank_2_tensor[:, -1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrank_2_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "rank_2_tensor(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]], shape=(4, 6), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]], shape=(4, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using `tf.gather` with `axis=1`, but wrong because tensor does not support -1 index\n",
    "rank_2_tensor = tf.reshape(tf.range(24), shape=(4, 6))\n",
    "print(rank_2_tensor)\n",
    "\n",
    "last_items_of_each_row = tf.gather(rank_2_tensor, indices=[-1], axis=1)\n",
    "print(last_items_of_each_row)\n",
    "tf.squeeze(last_items_of_each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]], shape=(4, 6), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 5]\n",
      " [11]\n",
      " [17]\n",
      " [23]], shape=(4, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 5, 11, 17, 23], dtype=int32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You'll need to calculate the last index, but not using -1\n",
    "\n",
    "# Using `tf.gather` with `axis=1`, but wrong because tensor does not support -1 index\n",
    "rank_2_tensor = tf.reshape(tf.range(24), shape=(4, 6))\n",
    "print(rank_2_tensor)\n",
    "\n",
    "last_items_of_each_row = tf.gather(rank_2_tensor, indices=[6-1], axis=1)\n",
    "print(last_items_of_each_row)\n",
    "tf.squeeze(last_items_of_each_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR** for `tf.gather()` and `tf.squeeze()`:\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 `tf.gather()`\n",
    "\n",
    "| Purpose                    | Grabs slices along an axis (like selecting rows or columns)        |\n",
    "|----------------------------|---------------------------------------------------------------------|\n",
    "| Common use                 | Select specific rows/columns (e.g., `axis=0` for rows, `axis=1` for columns) |\n",
    "| Negative indices support?  | ❌ No — unlike NumPy, `-1` does **not** mean \"last\"                 |\n",
    "| Fix for last index         | Use `tf.shape(tensor)[axis] - 1` instead of `-1`                   |\n",
    "| Example                    | `tf.gather(tensor, indices=[2], axis=1)` → gets column 2 from all rows |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 `tf.squeeze()`\n",
    "\n",
    "| Purpose                    | Removes dimensions with size 1 (e.g., shape `[4, 1]` → `[4]`)        |\n",
    "|----------------------------|-----------------------------------------------------------------------|\n",
    "| When to use it             | After slicing/gathering when you want to flatten out unnecessary dims |\n",
    "| Example                    | `tf.squeeze(tf.constant([[1], [2], [3]]))` → `[1, 2, 3]`             |\n",
    "| Optional axis              | You can specify `axis` if you only want to squeeze specific dimensions |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Example combo:\n",
    "\n",
    "```python\n",
    "last_col_index = tf.shape(tensor)[1] - 1\n",
    "last_column = tf.gather(tensor, indices=[last_col_index], axis=1)\n",
    "last_column = tf.squeeze(last_column)\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6, 1), dtype=int32, numpy=\n",
       "array([[[ 0],\n",
       "        [ 1],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 5]],\n",
       "\n",
       "       [[ 6],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [11]],\n",
       "\n",
       "       [[12],\n",
       "        [13],\n",
       "        [14],\n",
       "        [15],\n",
       "        [16],\n",
       "        [17]],\n",
       "\n",
       "       [[18],\n",
       "        [19],\n",
       "        [20],\n",
       "        [21],\n",
       "        [22],\n",
       "        [23]]], dtype=int32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in extra dimension to our rank 2 tensor\n",
    "\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR for `[..., tf.newaxis]`** 👇\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 `[..., tf.newaxis]`\n",
    "\n",
    "| Purpose                          | Adds a **new dimension** (axis of size 1) at the end of the tensor |\n",
    "|----------------------------------|---------------------------------------------------------------------|\n",
    "| Equivalent to                    | `tf.expand_dims(tensor, axis=-1)`                                  |\n",
    "| Useful for                       | - Adding channel dimensions (e.g., grayscale images)                |\n",
    "|                                  | - Preparing shape for broadcasting or model input                   |\n",
    "| Shape change                     | From `[a, b]` → `[a, b, 1]`                                         |\n",
    "| Can also insert in other axes   | Yes! Use slicing like `tensor[:, tf.newaxis, :]` to insert at axis 1 |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Example:\n",
    "\n",
    "```python\n",
    "x = tf.constant([1, 2, 3])        # shape: (3,)\n",
    "x_expanded = x[..., tf.newaxis]   # shape: (3, 1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Bonus: Why use `...`?\n",
    "\n",
    "- `...` is a shortcut for \"all previous dimensions\"\n",
    "- So `[..., tf.newaxis]` means: \"add a new axis at the very end\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6, 1), dtype=int32, numpy=\n",
       "array([[[ 0],\n",
       "        [ 1],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 5]],\n",
       "\n",
       "       [[ 6],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [11]],\n",
       "\n",
       "       [[12],\n",
       "        [13],\n",
       "        [14],\n",
       "        [15],\n",
       "        [16],\n",
       "        [17]],\n",
       "\n",
       "       [[18],\n",
       "        [19],\n",
       "        [20],\n",
       "        [21],\n",
       "        [22],\n",
       "        [23]]], dtype=int32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative to tf.newaxis\n",
    "tf.expand_dims(rank_2_tensor, axis=-1) # -1 means expand final axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 6), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]]], dtype=int32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=0)  # expand the 0-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 6), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5]],\n",
       "\n",
       "       [[ 6,  7,  8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15, 16, 17]],\n",
       "\n",
       "       [[18, 19, 20, 21, 22, 23]]], dtype=int32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=1)  # expand the 1-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23]], dtype=int32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=0)\n",
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Manipulating tensors (tensor operations)\n",
    "\n",
    "#### **Basic Operations**\n",
    "\n",
    "`+, -, *, /`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add values to a tensor using the addition operator\n",
    "tensor = tf.constant([[10, 7], [3, 4]])\n",
    "\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original tensor is unchanged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is unchanged!!\n",
    "\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant([[10, 7], [3, 4]])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]], dtype=int32)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication also works\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]], dtype=int32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substraction if you want\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use the tensorflow built-in function too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]], dtype=int32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original tensor unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matrix Multiplication**\n",
    "\n",
    "#### - the aboved operation is `element-wise` operation, not like `matrix multiplication`\n",
    "#### - In machine learning, matrix multiplication is one of the most common tensor operations - Like `dot product not necessarily element-wise`\n",
    "\n",
    "> There are two rules our tensors (or matrices) need to fulfill if we're going to matrix multiply them:\n",
    "> 1. The inner dimensions must match\n",
    "> 2. The resulting matrix has the shape of the `outer` dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]], dtype=int32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication in tensorflow\n",
    "print(tensor)\n",
    "tf.linalg.matmul(tensor, tensor)\n",
    "# tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  49],\n",
       "       [  9,  16]], dtype=int32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor  # this is element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication with Python operator \"@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]], dtype=int32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication with Python operator \"@\"\n",
    "#   it's called matrix multiplication\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor (3, 2) shape\n",
    "X = tf.reshape(tf.range(1, 7), shape=(3, 2))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 7,  8],\n",
       "       [ 9, 10],\n",
       "       [11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another (3, 2) tensor\n",
    "Y = tf.reshape(tf.range(7, 13), shape=(3, 2))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]], dtype=int32)>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 20:13:34.242127: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Try to matrix multiply tensors of same shape\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "# Try to matrix multiply tensors of same shape\n",
    "X @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 20:13:56.175880: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[149]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "tf.matmul(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]], dtype=int32)>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make the two matrices which being multiplied \"match\"\n",
    "X_T = tf.transpose(X)\n",
    "X_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[35, 44],\n",
       "       [44, 56]], dtype=int32)>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T @ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 5, 11, 17],\n",
       "       [11, 25, 39],\n",
       "       [17, 39, 61]], dtype=int32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ X_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product\n",
    "![Dot Product](./image/2025-03-24-20-30-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### reference vid sec 1 / 21 04:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  8,  9],\n",
       "       [10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's change the shape of Y\n",
    "tf.reshape(Y, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  9, 11],\n",
       "       [ 8, 10, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 2]), TensorShape([2, 3]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe the shapes\n",
    "X.shape, tf.reshape(Y, shape=(2, 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to multiply X by reshaped Y\n",
    "X @ tf.reshape(Y, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, tf.reshape(Y, shape=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 58,  64],\n",
       "       [139, 154]], dtype=int32)>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to change shape of X, instead of Y\n",
    "tf.matmul(tf.reshape(X, shape=(2, 3)), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3]), TensorShape([3, 2]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(X, shape=(2, 3)).shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose works for matmul, BUT NOTICE, contents are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can do the same with transpose, but contents different\n",
    "X, tf.transpose(X), tf.reshape(X, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try matrix multiplication with transpose rather than reshape\n",
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can do the same with transpose (however, result differs)\n",
    "X, tf.transpose(X), tf.reshape(X, shape=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 2]), TensorShape([3, 2]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try matrix multiplication with transpose rather than reshape\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(X) @ Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ tf.transpose(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 📓 **Resources** [Info and example of matrix multiplication](https://www.mathisfun.com/algebra/matrix-multiplying.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **The dot product**\n",
    "\n",
    "We can perform matrix multiplication using:\n",
    "```\n",
    "* tf.matmul()\n",
    "* tf.tensordot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]], dtype=int32)>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Perform the dot product on X and Y (requires X or Y to be transposed)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# (require X or Y to be transpose\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1254\u001b[39m, in \u001b[36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1253\u001b[39m   args, kwargs = replace_iterable_params(args, kwargs, iterable_params)\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m result = \u001b[43mapi_dispatcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m   1256\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mTypeError\u001b[39m: Missing required positional argument"
     ]
    }
   ],
   "source": [
    "# Perform the dot product on X and Y (requires X or Y to be transposed)\n",
    "# (require X or Y to be transpose\n",
    "\n",
    "tf.tensordot(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tensordot(tf.transpose(X), Y, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3, 2), dtype=int32, numpy=\n",
       "array([[[[ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]],\n",
       "\n",
       "        [[21, 24],\n",
       "         [27, 30],\n",
       "         [33, 36]],\n",
       "\n",
       "        [[35, 40],\n",
       "         [45, 50],\n",
       "         [55, 60]]],\n",
       "\n",
       "\n",
       "       [[[14, 16],\n",
       "         [18, 20],\n",
       "         [22, 24]],\n",
       "\n",
       "        [[28, 32],\n",
       "         [36, 40],\n",
       "         [44, 48]],\n",
       "\n",
       "        [[42, 48],\n",
       "         [54, 60],\n",
       "         [66, 72]]]], dtype=int32)>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tensordot(tf.transpose(X), Y, axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matrix multiplication between X and Y (transposed)\n",
    "tf.matmul(X, tf.transpose(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matrix multiplication between X and Y (reshaped)\n",
    "tf.matmul(X, tf.reshape(Y, shape=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Y:\n",
      "tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32) \n",
      "\n",
      "Y reshaped to (2, 3):\n",
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32) \n",
      "\n",
      "Y transposed:\n",
      "tf.Tensor(\n",
      "[[ 7  9 11]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Check the values of Y, reshape Y and transposed Y\n",
    "\n",
    "print(\"Normal Y:\")\n",
    "print(Y, \"\\n\")\n",
    "\n",
    "print(\"Y reshaped to (2, 3):\")\n",
    "print(tf.reshape(Y, (2, 3)), \"\\n\")\n",
    "\n",
    "print(\"Y transposed:\")\n",
    "print(tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Generally, when performing matrix multiplication on two tensors and one of the axes doesn't line up, you will transpose rather than reshape one of the tensors to get satisfy the matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Changing the datatype of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor with default datatype (float32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = tf.constant([7, 10])\n",
    "C.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### float32, float16, bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = tf.cast(B, dtype=tf.float16)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 7., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change from int32 to float32\n",
    "E = tf.cast(C, dtype=tf.float32)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([ 7., 10.], dtype=float16)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_float = tf.cast(E, dtype=tf.float16)\n",
    "E_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Aggregating Tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating tensors = condensing them from multiple values down to a smaller amount of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🦜 Bilingual Notes: Agregating Tensors\n",
    "\n",
    "---\n",
    "### 🔹 What does **\"aggregating\"** mean in TensorFlow?\n",
    "\n",
    "In TensorFlow, **\"aggregating\"** refers to **combining or summarizing multiple values**—for example, summing them, averaging them, or performing other reduction operations. This is used extensively in:\n",
    "\n",
    "- Loss calculation\n",
    "- Metric computation\n",
    "- Gradient updates\n",
    "- Distributed training\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 Simple Example: `tf.reduce_mean`\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "mean = tf.reduce_mean(x)\n",
    "print(mean)  # Output: 2.5\n",
    "```\n",
    "\n",
    "Here, `reduce_mean` **aggregates** all elements in the tensor and returns their average. Similar functions include `tf.reduce_sum`, `tf.reduce_max`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 Practical Example: Aggregating metrics with `tf.keras.metrics.Mean`\n",
    "\n",
    "```python\n",
    "m = tf.keras.metrics.Mean()\n",
    "\n",
    "m.update_state([1, 2, 3])\n",
    "m.update_state([4, 5])\n",
    "\n",
    "print(\"Mean result:\", m.result().numpy())  # Output: 3.0\n",
    "```\n",
    "\n",
    "Here, `Mean()` is an aggregator. Every time you call `update_state()`, it collects more values, and `result()` computes the overall average.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 Aggregation in Distributed Training\n",
    "\n",
    "If you're using multiple GPUs (or TPUs), TensorFlow will **aggregate values (e.g., gradients, loss) across devices** so that training remains consistent.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=64)\n",
    "```\n",
    "\n",
    "`compute_average_loss` aggregates per-example losses across devices to get a correct average loss for training.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Common Use Cases of Aggregating in TensorFlow\n",
    "\n",
    "| Use Case | Description |\n",
    "|----------|-------------|\n",
    "| **Loss Calculation** | Combine per-sample losses into a single scalar |\n",
    "| **Metric Computation** | Accumulate metrics (e.g., accuracy) across batches |\n",
    "| **Gradient Updates** | Combine gradients across GPUs in distributed training |\n",
    "| **Model Predictions** | Aggregate predictions from multiple models (e.g., ensemble averaging) |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 在 TensorFlow 裡面，「**aggregating**」這個詞的意思是 **彙總、聚合**，也就是將多個值（可能來自不同來源、批次、張量等）進行合併、統整成一個值或一個結構的動作。這個操作在許多場景都很重要，特別是在 **分散式訓練（Distributed Training）**、**loss 計算**、**梯度更新** 和 **指標評估（metrics evaluation）** 中。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 一個簡單的例子：`tf.reduce_mean`\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "mean = tf.reduce_mean(x)\n",
    "print(mean)  # Output: 2.5\n",
    "```\n",
    "\n",
    "這裡 `reduce_mean` 就是對張量 `x` 執行聚合操作：把所有元素「彙總」起來取平均。類似的還有 `tf.reduce_sum`、`tf.reduce_max` 等。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 更實用的例子：在 `tf.keras.metrics.Mean` 中使用 aggregation\n",
    "\n",
    "```python\n",
    "m = tf.keras.metrics.Mean()\n",
    "\n",
    "m.update_state([1, 2, 3])\n",
    "m.update_state([4, 5])\n",
    "\n",
    "print(\"Mean result:\", m.result().numpy())  # Output: 3.0\n",
    "```\n",
    "\n",
    "這裡 `Mean()` 指標會 **聚合（aggregate）多次輸入的值**，在訓練過程中你可以多次呼叫 `update_state()` 累積資料，最後呼叫 `result()` 得到整體的平均。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 在分散式訓練中常見的 aggregation：`tf.distribute.Strategy`\n",
    "\n",
    "假設你有多個 GPU，在每個 GPU 上訓練得到的 loss 或梯度可能不同，TensorFlow 會自動 **聚合（aggregate）所有設備的 loss/gradient**，確保你更新的權重是基於整體資訊。\n",
    "\n",
    "範例如下：\n",
    "\n",
    "```python\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=64)\n",
    "```\n",
    "\n",
    "這裡 `compute_average_loss` 就是一種 aggregation，把所有設備上計算出的 loss 進行平均。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Aggregating 的常見用途：\n",
    "\n",
    "| 場景 | 說明 |\n",
    "|------|------|\n",
    "| **loss 計算** | 多個樣本的 loss 聚合成一個平均 loss |\n",
    "| **metrics 評估** | 多個 batch 的 accuracy、precision 統計彙總 |\n",
    "| **梯度更新** | 分散式環境中各個 device 計算出的梯度進行加總或平均 |\n",
    "| **多輸入彙總** | 合併不同資料來源的值，例如多模型的預測結果進行加權平均 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10], dtype=int32)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values\n",
    "D = tf.constant([-7, -10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the absolute values\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go through the following forms of aggregation\n",
    "- Get the minimum\n",
    "- Get the maximum\n",
    "- Get the mean of tensor\n",
    "- Get the sum of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([99,  5, 60, 99, 50, 38, 40, 20, 21, 18, 42, 84, 82, 16, 65, 59, 19,\n",
       "       35, 62,  1, 53, 43, 87, 29, 45, 48, 74,  1, 42, 50, 60, 12, 16, 15,\n",
       "       44, 42, 64, 66, 52, 86, 22, 25, 11,  1, 87,  4, 28, 21, 27, 57])>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with values betwen 0 and 100 of size 100\n",
    "E = tf.constant(np.random.randint(0, 100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=50>, TensorShape([50]), 1)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(E), E.shape, E.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Find the minimum\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=99>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum\n",
    "tf.reduce_max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean\n",
    "tf.reduce_mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2127>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "tf.reduce_sum(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 🛠️ **Exercise:** With what we've just learned, find the variance and standard deviation of our `E` tensor using TensorFlow methods\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算方差\n",
    "variance_E = tf.math.reduce_variance(E)\n",
    "print(\"Variance of E:\", variance_E.numpy())\n",
    "\n",
    "# 计算标准差\n",
    "std_dev_E = tf.math.reduce_std(E)\n",
    "print(\"Standard Deviation of E:\", std_dev_E.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.random' has no attribute 'randint'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[201]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m E = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m(\u001b[32m0\u001b[39m, \u001b[32m100\u001b[39m, size=\u001b[32m50\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE Variance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.reduce_variance(E)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE variance (in NumPy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.reduce_variance(E).numpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'tensorflow._api.v2.random' has no attribute 'randint'"
     ]
    }
   ],
   "source": [
    "E = tf.random.randint(0, 100, size=50)\n",
    "print(f\"E Variance: {tf.reduce_variance(E)}\")\n",
    "print(f\"E variance (in NumPy): {tf.reduce_variance(E).numpy()}\")\n",
    "\n",
    "print(f\"E Standard Deviation: {tf.math.reduce_std(E)}\")\n",
    "print(f\"E Standard Deviation (in NumPy): {tf.math.reduce_std(E).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reduce_variance'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[202]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m E = tf.constant(np.random.randint(\u001b[32m0\u001b[39m, \u001b[32m100\u001b[39m, size=\u001b[32m50\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE Variance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_variance\u001b[49m(E)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE variance (in NumPy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.reduce_variance(E).numpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE Standard Deviation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.math.reduce_std(E)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'tensorflow' has no attribute 'reduce_variance'"
     ]
    }
   ],
   "source": [
    "E = tf.constant(np.random.randint(0, 100, size=50))\n",
    "print(f\"E Variance: {tf.reduce_variance(E)}\")\n",
    "print(f\"E variance (in NumPy): {tf.reduce_variance(E).numpy()}\")\n",
    "\n",
    "print(f\"E Standard Deviation: {tf.math.reduce_std(E)}\")\n",
    "print(f\"E Standard Deviation (in NumPy): {tf.math.reduce_std(E).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be either real or complex. Received integer type <dtype: 'int64'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[204]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m E = tf.constant(np.random.randint(\u001b[32m0\u001b[39m, \u001b[32m100\u001b[39m, size=\u001b[32m50\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE Variance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE variance (in NumPy): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.math.reduce_variance(E).numpy()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE Standard Deviation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf.math.reduce_std(E)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py:2599\u001b[39m, in \u001b[36mreduce_variance\u001b[39m\u001b[34m(input_tensor, axis, keepdims, name)\u001b[39m\n\u001b[32m   2597\u001b[39m means = reduce_mean(input_tensor, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m means.dtype.is_integer:\n\u001b[32m-> \u001b[39m\u001b[32m2599\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput must be either real or complex. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2600\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived integer type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeans.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2601\u001b[39m diff = input_tensor - means\n\u001b[32m   2602\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diff.dtype.is_complex:\n\u001b[32m   2603\u001b[39m   \u001b[38;5;66;03m# For complex values we need to take the absolute value before squaring.\u001b[39;00m\n\u001b[32m   2604\u001b[39m   \u001b[38;5;66;03m# This is achieved by multiplying with the conjugate.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: Input must be either real or complex. Received integer type <dtype: 'int64'>."
     ]
    }
   ],
   "source": [
    "E = tf.constant(np.random.randint(0, 100, size=50))\n",
    "print(f\"E Variance: {tf.math.reduce_variance(E)}\")\n",
    "print(f\"E variance (in NumPy): {tf.math.reduce_variance(E).numpy()}\")\n",
    "\n",
    "print(f\"E Standard Deviation: {tf.math.reduce_std(E)}\")\n",
    "print(f\"E Standard Deviation (in NumPy): {tf.math.reduce_std(E).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Fix: Cast our tensor to `tf.float32` or `tf.float64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[26. 29. 98. 21. 91. 36. 81. 34. 65. 40. 92.  2. 79. 56. 29. 23. 95. 15.\n",
      " 47.  1. 15. 16. 95.  3. 51.  0. 54. 15. 62.  4. 77. 64. 94. 86. 94. 58.\n",
      " 99. 64. 78.  0. 43. 68. 35. 18. 67. 72. 65. 81. 72. 34.], shape=(50,), dtype=float32)\n",
      "E Variance: 965.8656005859375\n",
      "E variance (in NumPy): 965.8656005859375\n",
      "E Standard Deviation: 31.078378677368164\n",
      "E Standard Deviation (in NumPy): 31.078378677368164\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "E = tf.constant(np.random.randint(0, 100, size=50), dtype=tf.float32)\n",
    "print(E)\n",
    "\n",
    "print(f\"E Variance: {tf.math.reduce_variance(E)}\")\n",
    "print(f\"E variance (in NumPy): {tf.math.reduce_variance(E).numpy()}\")\n",
    "\n",
    "print(f\"E Standard Deviation: {tf.math.reduce_std(E)}\")\n",
    "print(f\"E Standard Deviation (in NumPy): {tf.math.reduce_std(E).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=743.3504>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743.3504"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(E).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Aaron's comments on `Variance` and `Standard Deviation`:\n",
    "> Our results has something like below:\n",
    "> ```text\n",
    "> E Variance: 965.86\n",
    "> E Standard Deviation: 31.08\n",
    "> ```\n",
    "\n",
    "### 🤔 But our numbers of `E` are between 0 and 100?\n",
    "\n",
    "Yes, and that **doesn't contradict** the result — below is why.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Variance is not bounded by the data range\n",
    "\n",
    "The **variance** measures how spread out the values are from the **mean**.\n",
    "\n",
    "The formula is:\n",
    "\n",
    "\\[\n",
    "\\text{Variance} = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{x})^2\n",
    "\\]\n",
    "\n",
    "Even if all numbers are in `[0, 100)`, if they're very **spread out**, then the squared differences from the mean will be large.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Example\n",
    "\n",
    "Say our values are roughly spread from 0 to 100. The **mean** will be around 50. The squared difference from 0 to 50 is:\n",
    "\n",
    "\\[\n",
    "(0 - 50)^2 = 2500\n",
    "\\]\n",
    "\n",
    "Even a small number of such values will heavily affect the variance. But the **variance is the *mean* of those squared differences**, so even if the squared errors go from, say, 0 to 2500, the average can be around **900–1000** easily.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Key insight:\n",
    "\n",
    "If our data is **uniformly random between 0 and 100**, the theoretical population **variance** is:\n",
    "\n",
    "\\[\n",
    "\\text{Var}(U(0, 100)) = \\frac{(b - a)^2}{12} = \\frac{(100 - 0)^2}{12} = \\frac{10000}{12} \\approx 833.33\n",
    "\\]\n",
    "\n",
    "Our result:\n",
    "\n",
    "```\n",
    "965.86\n",
    "```\n",
    "\n",
    "is **very close to this**, considering sampling randomness from just 50 numbers!\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ And for Standard Deviation:\n",
    "\n",
    "\\[\n",
    "\\text{Std} = \\sqrt{Variance} \\approx \\sqrt{965} \\approx 31\n",
    "\\]\n",
    "\n",
    "Which matches our output: `31.078`\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Quick check in NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692.6035999999999 \n",
      " 26.31736308979302\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(0, 100, size=50)\n",
    "print(np.var(data), \"\\n\", np.std(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will likely give something close to:\n",
    "\n",
    "```text\n",
    "~900-1000 variance, ~30-32 std\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reduce_var'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[213]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the variance of our tensor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_var\u001b[49m(E)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'tensorflow' has no attribute 'reduce_var'"
     ]
    }
   ],
   "source": [
    "# Find the variance of our tensor\n",
    "tf.reduce_var(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[215]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the variance of our tensor, with the access to tensorflow_probability\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_probability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfp\u001b[39;00m\n\u001b[32m      4\u001b[39m tfp.stats.variance(E)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow_probability'"
     ]
    }
   ],
   "source": [
    "# Find the variance of our tensor, with the access to tensorflow_probability\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfp.stats.variance(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[219]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the standard deviation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tf.math.reduce_std(tf.cast(E, dtype=\u001b[43mfloat16\u001b[49m))\n",
      "\u001b[31mNameError\u001b[39m: name 'float16' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the standard deviation\n",
    "tf.math.reduce_std(tf.cast(E, dtype=float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=965.8656>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float16, numpy=31.08>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_std(tf.cast(E, dtype=tf.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bfloat16, numpy=964>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(tf.cast(E, dtype=tf.bfloat16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Find the positional maximum and minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔹 Aaron's comments on **Positional Maximum / Minimum**\n",
    "\n",
    "In TensorFlow (and NumPy), **positional maximum/minimum** refers to **finding the index (position)** where the **maximum or minimum value** occurs in a tensor or array — not the value itself, but *where* it is.\n",
    "\n",
    "| Function        | Returns               | Meaning                        |\n",
    "|----------------|------------------------|--------------------------------|\n",
    "| `tf.argmax()`  | Index of max value     | Positional maximum             |\n",
    "| `tf.argmin()`  | Index of min value     | Positional minimum             |\n",
    "| `tf.reduce_max()` | Actual max value    | Not positional                 |\n",
    "| `tf.reduce_min()` | Actual min value    | Not positional                 |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D tensor\n",
    "import tensorflow as tf\n",
    "x = tf.constant([3, 7, 2, 9, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [3 7 2 9 5]\n",
      "max_pos: 3\n"
     ]
    }
   ],
   "source": [
    "# ✅ Positional Maximum → `tf.argmax()`\n",
    "print(f\"x: {x}\")\n",
    "max_pos = tf.argmax(x)\n",
    "print(f\"max_pos: {max_pos.numpy()}\") # Output: 3 → because 9 is the max, and it's at index 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [3 7 2 9 5]\n",
      "main_pos: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ Positional Minimum → `tf.argmin()`\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "min_pos = tf.argmin(x)\n",
    "print(f\"main_pos: {min_pos.numpy()}\") # Output: 2 → because 2 is the min, and it's at index 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2d:\n",
      " [[1 9 3]\n",
      " [7 2 8]]\n",
      "\n",
      "tf.argmax(x2d): [1 0 1], because → argmax across rows for each column\n",
      "\n",
      "tf.argmax(x2d): [1 2], because → argmax across rows for each row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 🧩 Multidimensional Tensor Example\n",
    "\n",
    "x2d = tf.constant([[1, 9, 3],\n",
    "                   [7, 2, 8]])\n",
    "print(f\"x2d:\\n {x2d}\\n\")\n",
    "\n",
    "print(f\"tf.argmax(x2d): {tf.argmax(x2d, axis=0)}, because → argmax across rows for each column\\n\")  # → argmax across rows for each column\n",
    "print(f\"tf.argmax(x2d): {tf.argmax(x2d, axis=1)}, because → argmax across rows for each row\\n\")  # → argmax across rows for each row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of Aaron's Comments on Position Max/Min\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor for finding positional min and max\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "F = tf.random.uniform(shape=[10])\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=7>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the pos max\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8724445>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on our largest value position\n",
    "F[tf.argmax(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=4>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the pos min\n",
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.03366041>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on our smallest value position\n",
    "F[tf.argmin(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8724445, 0.03366041)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[tf.argmax(F)].numpy(), F[tf.argmin(F)].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for equality\n",
    "F[tf.argmax(F)] == tf.reduce_max(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Equality\n",
    "F[tf.argmin(F)] == tf.reduce_min(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Squeezing a Tensor （Removing all single dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor to get started\n",
    "G = tf.constant(tf.random.uniform(shape=[50]), shape=(1, 1, 1, 1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 1, 50])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       " array([0.68789124, 0.48447883, 0.9309944 , 0.252187  , 0.73115396,\n",
       "        0.89256823, 0.94674826, 0.7493341 , 0.34925628, 0.54718256,\n",
       "        0.26160395, 0.69734323, 0.11962581, 0.53484344, 0.7148968 ,\n",
       "        0.87501776, 0.33967495, 0.17377627, 0.4418521 , 0.9008261 ,\n",
       "        0.13803864, 0.12217975, 0.5754491 , 0.9417181 , 0.9186585 ,\n",
       "        0.59708476, 0.6109482 , 0.82086265, 0.83269787, 0.8915849 ,\n",
       "        0.01377225, 0.49807465, 0.57503664, 0.6856195 , 0.75972784,\n",
       "        0.908944  , 0.40900218, 0.8765154 , 0.53890026, 0.42733097,\n",
       "        0.401173  , 0.66623247, 0.16348064, 0.18220246, 0.97040176,\n",
       "        0.06139731, 0.53034747, 0.9869994 , 0.4746945 , 0.8646754 ],\n",
       "       dtype=float32)>,\n",
       " TensorShape([50]))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_squeezed = tf.squeeze(G)\n",
    "G_squeezed, G_squeezed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of indices\n",
    "some_list = [0, 1, 2, 3]  # could be red, green, blue, purple\n",
    "\n",
    "# One hot encode out list of indices\n",
    "tf.one_hot(some_list, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'yo I love deep learning', b'so sorry', b'so sorry',\n",
       "        b'so sorry'],\n",
       "       [b'so sorry', b'yo I love deep learning', b'so sorry',\n",
       "        b'so sorry'],\n",
       "       [b'so sorry', b'so sorry', b'yo I love deep learning',\n",
       "        b'so sorry'],\n",
       "       [b'so sorry', b'so sorry', b'so sorry',\n",
       "        b'yo I love deep learning']], dtype=object)>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify custom values for one hot encoding\n",
    "tf.one_hot(some_list, depth=4, on_value=\"yo I love deep learning\", off_value=\"so sorry\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Squaring, log, square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tensor \n",
    "H = tf.range(1, 10)\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81], dtype=int32)>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Square it\n",
    "tf.square(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[263]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the squaretoot\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt] name: "
     ]
    }
   ],
   "source": [
    "# Find the squaretoot\n",
    "tf.sqrt(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([1.       , 1.4142135, 1.7320508, 2.       , 2.236068 , 2.4494898,\n",
       "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the squareroot - change to float\n",
    "tf.sqrt(tf.cast(H, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Log}}; Op<name=Log; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Log] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[265]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the lgo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[39m, in \u001b[36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     87\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py:5681\u001b[39m, in \u001b[36mlog\u001b[39m\u001b[34m(x, name)\u001b[39m\n\u001b[32m   5679\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   5680\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m5681\u001b[39m   \u001b[43m_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5682\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   5683\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tf-dev/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Log}}; Op<name=Log; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Log] name: "
     ]
    }
   ],
   "source": [
    "# Find the lgo\n",
    "tf.math.log(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float16, numpy=\n",
       "array([0.    , 0.6934, 1.099 , 1.387 , 1.609 , 1.792 , 1.946 , 2.08  ,\n",
       "       2.197 ], dtype=float16)>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the log\n",
    "tf.math.log(tf.cast(H, dtype=tf.float16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Tensors and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow interacts beautifully with Numpy arrays\n",
    "\n",
    "#### 🔑 **Note:** One of the main deffierences between a TensorFlow tensor and a NumPy array is that a TensoprFlow tensor can be run on a GPU or TPU (for faster numerical processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor directly from a numpy array\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert out tensor back to a numpy array\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor J to a NumPy array\n",
    "J.numpy(), type(J.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default tyupes of each are slightly different\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.]))\n",
    "tensor_J = tf.constant([3., 7., 10.])\n",
    "\n",
    "# Check dtype of each\n",
    "numpy_J.dtype, tensor_J.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Access to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access to GPU for `Mac` `M1`, `M2`, `M3` Apple Silicon GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[271]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#check for gpu\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m.backends.mps.is_available():\n\u001b[32m      3\u001b[39m    mps_device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m    x = torch.ones(\u001b[32m1\u001b[39m, device=mps_device)\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#check for gpu for Pytorch\n",
    "if torch.backends.mps.is_available():\n",
    "   mps_device = torch.device(\"mps\")\n",
    "   x = torch.ones(1, device=mps_device)\n",
    "   print (x)\n",
    "else:\n",
    "   print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  details = tf.config.experimental.get_device_details(gpus[0])\n",
    "  print(\"GPU details: \", details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "-----------------------\n",
      "{'current': 0, 'peak': 0}\n",
      "GPU details:  {'device_name': 'METAL'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "print('-----------------------')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  details = tf.config.experimental.get_device_details(gpus[0])\n",
    "  print(tf.config.experimental.get_memory_info('GPU:0'))\n",
    "  print(\"GPU details: \", details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'current': 0, 'peak': 0}\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  # Returns a dict in the form {'current': <current mem usage>,\n",
    "  #                             'peak': <peak mem usage>}\n",
    "  print(tf.config.experimental.get_memory_info('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
       " LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open -a \"Activity Monitor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1l\u001b>    WindowManage 5.3  22:27.42 5      2    339   37M- \u001b[24;68H5M-   57273  K[19;23H9\u001b[19;33H9\u001b[19;57H+\u001b[19;68H7\u001b[15;22H7.0\u001b[15;37H/1\u001b[16;24H5\u001b[7C64 23/1\u001b[16;55H6\u001b[16;69H1\u001b[17;21H8.8\u001b[17;32H5\u001b[17;68H584K-21H4\u001b[22;48H59-\u001b[22;71H+total, 640K\u001b[6P\u001b[5;23H6\u001b[5;34H501\u001b[5;52H68\u001b[6;7H9\u001b[6;44H345(60) swapins, 11321832(0) swapouts\u001b[7;26H12\u001b[7;46H58\u001b[8;13H386\u001b[8;34H67\u001b[10;51HT MEM    PURG   CMPRS  PGRP  \u001b[1;23H3\u001b[1;36H0\u001b[1;51H2\u001b[27C8\u001b[2;41H3.29\u001b[2;53H7.2\u001b[2;65H9.42\u001b[4;13H0 total, 0B\u001b[3P\u001b[5;21H489\u001b[5;35H32\u001b[5;53H0\u001b[6;44H413(68\u001b[7;27H69\u001b[7;46H89\u001b[8;13H427\u001b[8;34H729\u001b[1;23H4\u001b[1;34H1 stuck, 578 sleeping, 5640 threads\u001b[10C9\u001b[2;13H46, 4.65, 4.04\u001b[2;43H36\u001b[2;53H9.32\u001b[2;65H7.30\u001b[5;21H514\u001b[5;34H620\u001b[5;52H7\u001b[6;45H33(20\u001b[7;27H96\u001b[7;45H708\u001b[8;14H48\u001b[8;35H75\u001b[11;22H3.5\u001b[11;33H8\u001b[11;48H805+ 1896M-\u001b[11;69H0\u001b[12;21H32.5\u001b[12;37H8/10\u001b[13;21H20.1\u001b[7C95\u001b[13;57H+\u001b[1;23H2\u001b[1;34H581 sleeping, 5633 threads         \u001b[9C20\u001b[2;41H5.55\u001b[2;53H11.98% sys, 72.46% idle\u001b[5;21H451\u001b[5;34H595\u001b[5;52H58\u001b[6;43H8069(636) swapins, 11321832(0) swapout\u001b[7;26H232\u001b[7;46H34\u001b[8;13H610\u001b[8;34H82\u001b[1;23H7\u001b[1;34H1 stuck, 575 sleeping, 5625 threads\u001b[10C2\u001b[2;43H90\u001b[2;56H23\u001b[2;68H8\u001b[5;21H517\u001b[5;34H626\u001b[5;52H69\u001b[6;44H161(92) swapins, 11321832(0) swapouts\u001b[7;27H48\u001b[7;47H7\u001b[8;13H768\u001b[8;34H929\u001b[1;14H5\u001b[1;23H8\u001b[1;34H577 sleeping, 5694 threads         \u001b[10C3\u001b[2;41H9.69\u001b[2;54H3.55\u001b[7C66.75\u001b[4;13H91 total, 2704K resident, 69M private, 1325M shared.\u001b[5;23H2\u001b[5;34H812\u001b[5;52H77\u001b[6;6H60\u001b[6;44H317(156) swapins, 11322392(560) swapo\u001b[7;26H319\u001b[7;45H804\u001b[8;12H3481\u001b[8;31H500154\u001b[1;23H3\u001b[1;35H82\u001b[1;51H9\u001b[27C4\u001b[2;13H74, 4.74, 4.07\u001b[2;41H2.57\u001b[2;53H9.14% sys, 78.28\u001b[1P\u001b[4;13H0 total, 0B\u001b[4P\u001b[04\u001b[5;35H00\u001b[5;53H4\u001b[6;45H33(16) swapins, 11323240(848) swapou\u001b[7;27H85\u001b[7;46H71\u001b[8;14H97\u001b[8;34H439\u001b[1;14H7\u001b[1;23H14 running, 573 sleeping, 5699 threads\u001b[18C5\u001b[2;41H6.95\u001b[2;53H12.8\u001b[2;65H0.96\u001b[4;13H66 total, 2128K resident, 69M private, 1326M shared.\u001b[5;21H485\u001b[5;35H11\u001b[6;45H65(32\u001b[6;70H0) swapouts\u001b[7;26H467\u001b[7;45H944\u001b[8;13H562\u001b[8;34H570\u001b[1;13H90\u001b[1;24H3\u001b[1;37H7\u001b[1;50H705\u001b[26C6\u001b[2;41H4.98\u001b[2;53H9.2% sys, 75.99\u001b[1P\u001b[4;13H108 total, 3968K resident, 69M private, 1326M shared.\u001b[5;22H9\u001b[5;35H22\u001b[5;52H80\u001b[6;7H2\u001b[6;44H401(36\u001b[6;65H4560(1320) swapo\u001b[7;27H81\u001b[7;46H51\u001b[8;13H626\u001b[8;34H958\u001b[1;23H4 running, 586 sleeping, 5700 threads \u001b[18C7\u001b[2;43H8% user, 9.3% sys, 76.88\u001b[1P\u001b[3;15H5\u001b[3;30H8\u001b[3;40H4\u001b[4;13H0 total, 0B resident, 0B\u001b[6P\u001b[5;21H500\u001b[5;35H17\u001b[5;53H3\u001b[6;45H93(92\u001b[6;66H668(108) swapou\u001b[7;26H528\u001b[7;46H94\u001b[8;14H51\u001b[8;33H1039\u001b[11;21H37\u001b[11;37H  \u001b[11;48H494- 1899M- 2752K-\u001b[12;21H30.5\u001b[12;56H-\u001b[1;34H1 stuck, 585 sleeping, 5671 threads\u001b[10C8\u001b[2;41H3.1\u001b[2;52H7.91% sys, 79.6\u001b[5;21H49\u001b[5;34H752\u001b[5;52H99\u001b[6;44H521(28\u001b[6;65H5044(376\u001b[7;26H606\u001b[7;44H9089\u001b[8;13H72\u001b[8;34H246\u001b[11;22H9.6\u001b[11;37H/1\u001b[11;50H0- 1903M+\u001b[6C  856\u001b[12;21H29.9\u001b[12;56H \u001b[1;14H1\u001b[1;23H10 running, 1 stuck, 580 sleeping, 5683 threads\u001b[9C9\u001b[2;13H28, 4.68, 4.06\u001b[2;41H2.56% user, 6.55% sys, 80.87% idle\u001b[4;13H220 total, 12M resident, 0B private, 1338M shared.\u001b[5;21H522\u001b[5;35H31\u001b[5;52H64\u001b[6;44H621(100) swapins, 11325044(0) swapout\u001b[7;27H60\u001b[7;45H13\u001b[8;13H808\u001b[8;35H80\u001b[11;21H29.0\u001b[11;33H2 23/2   6/1\u001b[6C  1898M- 880K-  855\u001b[1;13H87\u001b[1;23H2 running, 585 sleeping, 5647 threads          \u001b[8C31\u001b[2;41H4.4% user, 8.46% sys, 77.49\u001b[1P\u001b[4;13H0 total, 0B\u001b[3P\u001b[5;21H490\u001b[5;35H2\u001b[5;52H72\u001b[6;7H0\u001b[6;45H80(59) swapins, 11325044(0) swapouts\u001b[7;26H79\u001b[7;46H92\u001b[8;13H914\u001b[8;34H326\u001b[11;21H40.9\u001b[11;37H     6    7485- 1897\u001b[7C \u001b[1;23H5\u001b[1;34H1 stuck, 581 sleeping, 5648 threads\u001b[10C2\u001b[2;43H84% user, 9.10% sys, 76.4\u001b[5;22H58\u001b[5;35H18\u001b[5;52H89\u001b[6;44H784(104) swapins, 11325044(0) swapout\u001b[7;26H924\u001b[7;45H261\u001b[8;14H61\u001b[8;35H80\u001b[11;24H4\u001b[11;33H3\u001b[11;49H97+\u001b[11;60H1072K+\u001b[12;21H33.5\u001b[13;32H53\u001b[13;57H \u001b[13;69H0\u001b[14;22H8.6\u001b[14;69H7M+\u001b[1;14H4\u001b[1;23H3\u001b[1;45H0\u001b[1;59H35\u001b[18C3\u001b[2;41H2.50\u001b[2;53H6.79\u001b[7C80.70% idle\u001b[5;22H85\u001b[5;34H69\u001b[5;52H67\u001b[6;6H59\u001b[6;44H804(20) swapins, 11325044(0) swapouts\u001b[7;27H97\u001b[7;45H319\u001b[8;14H87\u001b[8;34H439\u001b[11;22H6.6\u001b[11;50H8+ 1903M+\u001b[6C  854\u001b[12;21H20.7\u001b[12;40H2\u001b[13;24H3\u001b[7C74\u001b[13;57H+\u001b[14;22H7\u001b[14;37H/1\u001b[14;57H-\u001b[14;71H-\u001b[15;22H5.8\u001b[7C22 23  \u001b[15;54H58M-\u001b[15;69H4M-\u001b[1;23H5\u001b[1;34H579 sleeping, 5663 threads         \u001b[10C4\u001b[2;13H58, 4.76, 4.09\u001b[2;41H3.39\u001b[2;53H11.33% sys, 75.26% idle\u001b[5;22H90\u001b[5;35H65\u001b[5;52H86\u001b[6;45H80(76\u001b[7;25H5110\u001b[7;45H422\u001b[8;12H4123\u001b[8;34H793\u001b[11;22H3.7\u001b[11;33H4 22/1   5\u001b[7C3- 1897M-\u001b[11;69H2\u001b[12;21H31.8\u001b[12;33H4\u001b[6C0\u001b[1;14H5\u001b[1;23H3\u001b[1;35H82\u001b[1;50H89\u001b[27C5\u001b[2;41H9.10\u001b[2;54H9.10\u001b[7C61.78\u001b[4;13H254 total, 15M resident, 0B private, 1340M shared.\u001b[5;21H501\u001b[5;34H743\u001b[5;53H8\u001b[6;6H60\u001b[6;42H52075(3195) swapins, 11325044(0) swapou\u001b[7;27H46\u001b[7;46H43\u001b[8;12H5661\u001b[8;34H8\u001b[1;14H4\u001b[1;23H8\u001b[1;35H76\u001b[1;49H710\u001b[27C6\u001b[2;41H4.74\u001b[2;54H2.52\u001b[7C72.73\u001b[4;13H0 total, 0B\u001b[3P\u001b[5;21H474\u001b[5;35H0\u001b[5;52H7\u001b[6;6H59\u001b[6;44H307(232) swapins, 11325044(0) swapout\u001b[7;27H95\u001b[7;46H86\u001b[8;13H923\u001b[8;33H2012\u001b[11;21H45.1\u001b[11;36H78/10\u001b[11;56H-\u001b[1;23H3\u001b[1;35H81\u001b[1;50H2\u001b[28C7\u001b[2;41H2.4\u001b[2;54H1.26\u001b[2;66H6.29\u001b[5;22H93\u001b[5;35H19\u001b[5;52H90\u001b[6;44H919(61\u001b[7;26H287\u001b[7;45H580\u001b[8;12H6127\u001b[8;34H151\u001b[11;21H53.2\u001b[11;33H6 779\u001b[11;56H+\u001b[12;22H2.1\u001b[12;33H5 22  \u001b[12;48H440- 1899M-\u001b[12;69H0\u001b[13;22H8.3\u001b[7C49\u001b[13;57H \u001b[14;22H7.8\u001b[14;57H   0B-    166\u001b[15;22H6\u001b[15;32H78\u001b[15;55H1M-\u001b[15;67H53\u001b[1;14H5\u001b[1;23H5\u001b[1;36H0\u001b[1;50H3\u001b[28C8\u001b[2;41H1.31\u001b[2;54H2.95\u001b[2;66H5.72\u001b[3;15H9\u001b[3;30H9\u001b[3;40H5\u001b[4;13H45 total, 6048K resident, 864K private, 1340M shared.\u001b[5;22H84\u001b[5;35H33\u001b[5;53H6\u001b[6;6H60\u001b[6;45H55(36) swapins, 11325044(0) swapouts\u001b[7;26H469\u001b[7;45H748\u001b[8;13H223\u001b[8;34H206\u001b[11;21H25.0\u001b[11;37H8\u001b[12;21H22.0\u001b[12;49H38- 1896M- 6416K+ 851M+\u001b[13;22H7.5\u001b[7C68\u001b[13;57H-\u001b[14;22H6.1\u001b[14;57H+  0B \u001b[6C7\u001b[15;22H0\u001b[15;32H90\u001b[15;55H4M+\u001b[15;68H43\u001b[1;14H6\u001b[1;23H2\u001b[1;36H4\u001b[1;50H15\u001b[27C9\u001b[2;13H37, 4.75\u001b[2;41H4.89\u001b[2;54H5.51\u001b[7C69.59\u001b[4;13H122 total, 5040K resident, 864K private, 1340M shared.\u001b[5;21H502\u001b[5;35H71\u001b[5;52H84\u001b[6;43H3055(100) swapins, 11325044(0) swapout\u001b[7;27H83\u001b[7;46H59\u001b[8;13H470\u001b[8;35H39\u001b[1;14H5\u001b[1;36H3\u001b[1;50H09\u001b[26C41\u001b[2;41H3.48\u001b[2;54H0.7% sys, 76.43\u001b[1P\u001b[4;13H0 total, 0B\u001b[5P\u001b[11\u001b[5;35H99\u001b[5;52H71\u001b[6;45H91(36) swapins, 11325044(0) swapouts\u001b[7;26H515\u001b[7;46H81\u001b[8;14H94\u001b[8;35H94\u001b[1;14H4\u001b[1;23H3\u001b[1;36H1\u001b[1;49H688\u001b[27C2\u001b[2;41H2.23\u001b[2;56H0\u001b[2;65H7.76\u001b[5;21H440\u001b[5;35H52\u001b[5;52H80\u001b[6;6H59\u001b[6;44H187(9\u001b[7;27H57\u001b[7;45H814\u001b[8;13H533\u001b[8;34H332\u001b[1;34H1 stuck, 580 sleeping, 5682 threads\u001b[10C3\u001b[2;41H4.89\u001b[2;54H1.96% sys, 73.13% idle\u001b[5;22H86\u001b[5;34H800\u001b[5;52H73\u001b[6;44H203(1\u001b[7;26H602\u001b[7;46H57\u001b[8;14H62\u001b[8;34H460\u001b[1;14H3\u001b[1;23H4\u001b[1;34H579 sleeping, 5760 threads         \u001b[10C4\u001b[2;11H5.86, 4.67, 4.07\u001b[2;41H3.51\u001b[2;54H2.8% sys, 74.39\u001b[1P\u001b[5;21H524\u001b[5;34H771\u001b[5;52H69\u001b[6;7H7\u001b[6;44H383(180) swapins, 11331816(6772) swap\u001b[7;27H17\u001b[7;46H60\u001b[8;13H721\u001b[8;33H4287\u001b[1;23H2\u001b[1;34H1 stuck, 580 sleeping, 5716 threads\u001b[10C5\u001b[2;41H0.47\u001b[2;53H6.14\u001b[7C83.37\u001b[5;22H00\u001b[5;34H819\u001b[5;52H98\u001b[6;45H99(16) swapins, 11331816(0) swapouts\u001b[7;26H715\u001b[7;45H948\u001b[8;12H7272\u001b[8;34H448\u001b[1;23H16 running, 567 sleeping, 5709 threads        \u001b[10C6\u001b[2;41H4.6\u001b[2;53H8.2\u001b[2;64H77.8\u001b[1P\u001b[5;21H487\u001b[5;35H02\u001b[5;52H86\u001b[6;44H487(88\u001b[6;65H3560(1744) swapo\u001b[7;26H913\u001b[7;43H9007\u001b[8;13H337\u001b[8;34H965\u001b[1;23H4 running, 1 stuck, 578 sleeping, 5713 threads\u001b[10C7\u001b[2;41H3.81\u001b[2;53H9.7\u001b[2;65H6.43% idle\u001b[5;23H5\u001b[5;34H758\u001b[5;52H99\u001b[6;44H503(16\u001b[6;70H0) swapouts\u001b[7;25H6019\u001b[7;45H103\u001b[8;12H8136\u001b[8;33H500\u001b[11;21H40.3\u001b[11;37H  \u001b[11;50H4- 1900M- 1072K- 844\u001b[1;23H8\u001b[1;34H575 sleeping, 5644 threads         \u001b[10C9\u001b[2;43H58\u001b[2;53H14.87% sys, 71.53% idle\u001b[5;21H532\u001b[5;34H644\u001b[5;53H0\u001b[6;44H643(140) swapins, 11333560(0) swapout\u001b[7;27H31\u001b[7;46H12\u001b[8;13H282\u001b[8;34H196\u001b[1;23H6\u001b[1;36H7\u001b[1;49H711\u001b[26C50\u001b[2;11H7.95, 5.13, 4.23\u001b[2;41H7.65\u001b[2;54H3\u001b[2;65H68.46\u001b[3;15H8\u001b[3;40H4\u001b[4;35H0B\u001b[2P\u001b[5;22H48\u001b[5;35H81\u001b[5;52H105M unused.\u001b[6;44H731(88) swapins, 11333560(0) swapouts\u001b[7;27H56\u001b[7;46H34\u001b[8;13H514\u001b[8;34H283\u001b[11;21H60.8\u001b[7C20\u001b[12;21H44.5\u001b[12;36H2/1   5\u001b[6C47+ 1923M+ 2752K- 851M-\u001b[24;1H\u001b[2J\u001b[?47l\u001b8"
     ]
    }
   ],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a typo - Display has s => Displays => SPDisplay`s`DataType\n",
    "!system_profiler SPDisplayDataType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphics/Displays:\n",
      "\n",
      "    Apple M1 Pro:\n",
      "\n",
      "      Chipset Model: Apple M1 Pro\n",
      "      Type: GPU\n",
      "      Bus: Built-In\n",
      "      Total Number of Cores: 16\n",
      "      Vendor: Apple (0x106b)\n",
      "      Metal Support: Metal 3\n",
      "      Displays:\n",
      "        Color LCD:\n",
      "          Display Type: Built-in Liquid Retina XDR Display\n",
      "          Resolution: 3024 x 1964 Retina\n",
      "          Main Display: Yes\n",
      "          Mirror: Off\n",
      "          Online: Yes\n",
      "          Automatically Adjust Brightness: Yes\n",
      "          Connection Type: Internal\n",
      "        VA2403-FHD:\n",
      "          Resolution: 1920 x 1080 (1080p FHD - Full High Definition)\n",
      "          UI Looks like: 1920 x 1080 @ 60.00Hz\n",
      "          Mirror: Off\n",
      "          Online: Yes\n",
      "          Rotation: Supported\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!system_profiler SPDisplaysDataType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "!system_profiler SPDisplayDataType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** Note:** If you have access to a CUDA-enabled GPU, TensorFlow will automatically use it whenever possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-dev",
   "language": "python",
   "name": "tf-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
